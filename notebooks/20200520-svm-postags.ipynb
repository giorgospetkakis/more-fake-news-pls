{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data\n",
    "import spacy\n",
    "from utils import go_to_project_root\n",
    "import numpy as np\n",
    "import re\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "authors = data.get_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "author= authors['14ka43f4ho6puh4iyhrfzsbrdpy5yixi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __clean_tweets__(tweets, pattern=None, clean_USER=False):\n",
    "\tpattern = r\"HASHTAG|URL|RT|#|https:\\/\\/t\\.\\\\[a-z\\d]+|https.*$|\\&*amp\"\n",
    "\tif clean_USER:\n",
    "\t\tpattern += r\"|USER\"\n",
    "\tclean_tweets = []\n",
    "\tfor tweet in tweets:\n",
    "\t\tclean = re.sub(pattern, '', tweet)\n",
    "\t\tclean = emoji.get_emoji_regexp().sub(r'', clean)\n",
    "\t\tclean = clean.strip()\n",
    "\t\tclean_tweets.append(clean)\n",
    "\n",
    "\treturn clean_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Ô∏èÔ∏èÔ∏è That's right--proud of it too!\"]\n",
      "Ô∏èÔ∏èÔ∏è That's right--proud of it too!\n",
      "üíóüéûÔ∏èüé•üíóüéûÔ∏èüé•üíóüéûÔ∏èüé• That's right--proud of it too! #URL# #URL#\n",
      "[\"Ô∏èÔ∏èÔ∏è That's right--proud of it too!\"]\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "cleaned = __clean_tweets__([author.tweets[17]])\n",
    "print(cleaned)\n",
    "print(cleaned[0])\n",
    "re.split('[ -]', cleaned[0])\n",
    "str_list = len(list(filter(None, re.split('[ -]', cleaned[0]))))\n",
    "\n",
    "print(author.tweets[17])\n",
    "print(cleaned)\n",
    "print(str_list)\n",
    "print(len(author.tweets[17].split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëçüòÆüëçüòÆ Who would have guessed?! #URL# #HASHTAG# #HASHTAG# #HASHTAG# #HASHTAG# #HASHTAG#‚Ä¶ #URL#\n",
      "Who would have guessed?!      ‚Ä¶\n",
      "['PRON', 'VERB', 'AUX', 'VERB', 'PUNCT', 'PUNCT', 'SPACE', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "cleaned = __clean_tweets__(author.tweets)\n",
    "author.POS_tags = []\n",
    "author.tokens = []\n",
    "for tweet in nlp.pipe(cleaned, disable=['parser']):\n",
    "    #Collect and save tags\n",
    "    tags = []\n",
    "    text = []\n",
    "    tags.append([str(token.pos_) for token in tweet])\n",
    "    text.append([str(token.text) for token in tweet])\n",
    "    author.POS_tags.append(tags[0])\n",
    "    author.tokens.append(text[0])\n",
    "    \n",
    "print(author.tweets[0])\n",
    "print(cleaned[0])\n",
    "print([tag for tag in author.POS_tags[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'SPACE_mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-a9a82e47df16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauthor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOS_counts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SPACE_mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'SPACE_mean'"
     ]
    }
   ],
   "source": [
    "author.POS_counts['SPACE_mean']\n",
    "author.POS_counts.pop('SPACE_mean')\n",
    "author.POS_cou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(author.tweets)\n",
    "\n",
    "adjectives = {}\n",
    "author.POS_counts = {}\n",
    "\n",
    "tag_list = ['ADJ' ,'ADP', 'ADV', 'AUX' , 'CONJ' , 'CCONJ' , 'DET' , 'INTJ' , 'NOUN' , 'NUM' , 'PART' , 'PRON' , 'PROPN' , 'PUNCT' , 'SCONJ' , 'SYM' , 'VERB' ,'X' , 'SPACE', 'TOKEN']\n",
    "for tag in tag_list:\n",
    "    author.POS_counts['{}_mean'.format(tag)] = 0\n",
    "    #author.POS_counts['{}_max'.format(tag)] = 0\n",
    "    \n",
    "for i_tweet in range(len(author.POS_tags)):\n",
    "     for j_tag in range(len(author.POS_tags[i_tweet])):\n",
    "            author.POS_counts['{}_mean'.format(author.POS_tags[i_tweet][j_tag])] += 1/N\n",
    "            author.POS_counts['TOKEN_mean'] += 1/N\n",
    "            if author.POS_tags[i_tweet][j_tag] == 'ADJ':\n",
    "                if author.tokens[i_tweet][j_tag].lower() in adjectives.keys():\n",
    "                    adjectives[author.tokens[i_tweet][j_tag].lower()] += 1\n",
    "                else:\n",
    "                    adjectives[author.tokens[i_tweet][j_tag].lower()] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In 2002, Steven Spielberg finally finished college after a 33-year hiatus. He turned in Schindler's List for h‚Ä¶\""
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In 2002, Steven Spielberg finally finished college after a 33-year hiatus. He turned in Schindler's List for h‚Ä¶ #URL#\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_cleaned[9].strip()autho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"üëçüòÆüëçüòÆ In 2002, Steven Spielberg finally finished college after a 33-year hiatus. He turned in Schindler's List for h‚Ä¶ #URL#\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author.tweets[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in author.POS_tags[5]:\n",
    "    for item in tag:\n",
    "        print(item)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tag in author.POS_tags[0][0]:\n",
    "    for whatever in tag:\n",
    "        print(whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
